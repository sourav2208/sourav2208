{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "Ag9LCva-p1cl",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourav2208/sourav2208/blob/main/Classification_IndiGo_Airline_Passenger_Referral_Prediction_by_s_r_thakur.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Classification - IndiGo Airline Passenger Referral Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##### **Contribution**    - Individual\n",
        "Project by - Sourav Ranjan Thakur"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/sourav2208/sourav2208"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this machine learning project is to classify airlines into categories based on certain features or attributes. Classification can serve multiple purposes, such as identifying potential partners for codeshare agreements, assisting in pricing strategies, or aiding in market analysis. In this project, We will be exploring if flyers would recommend the airline to their friends and families, based on their travel experience,reviews and ratings.\n",
        "\n",
        "#### There are few problems that we are looking in this project:\n",
        "\n",
        "* Develop a classification model to categorize airlines based on the likelihood of customers recommending them to friends and family.\n",
        "\n",
        "* Recognize the pivotal role of customer satisfaction and referrals in the growth and success of airlines.\n",
        "\n",
        "* Enable airlines to strategically utilize customer referral information for codeshare agreements, pricing strategies, and market analysis.\n",
        "\n",
        "* Identify customers likely to refer the airline, a task complicated by the diverse factors influencing satisfaction and referrals.\n",
        "\n",
        "* Assess the model's capability to provide actionable insights for airlines to tailor services, improve customer satisfaction, and enhance brand reputation.\n",
        "\n",
        "\n",
        "This problem statement outlines the key objectives, challenges, and considerations for developing a classification model to predict customer referrals in the airline industry."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "id": "u7hh8p29zr19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import datetime as dt\n",
        "import missingno as msno\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import f_oneway\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score,accuracy_score,precision_score,recall_score,f1_score,confusion_matrix\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV , cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EZSebEeCz60q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df1 = pd.read_excel('/content/drive/MyDrive/data_airline_reviews.xlsx')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df1.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df1.info()\n"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df1.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "#Visualizing Missing Values\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.heatmap(df1.isnull(), cbar=False, cmap='YlGnBu')\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.xticks(rotation=30)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Data includes airline reviews from 2006 to 2019 for popular airlines around the world with user feedback ratings and reviews based on their travel experience.\n",
        "\n",
        "It has 131895 rows 17 different columns.\n",
        "\n",
        "Data is scraped in Spring 2019. Feature descriptions briefly as follows:\n",
        "\n",
        "1. **airline** - Airline name\n",
        "2. **overall** - Overall score\n",
        "3. **Author** - Author information\n",
        "4. **review_date** - Customer Review posted date\n",
        "5. **Customer_review** - Actual customer review(Textual)\n",
        "6. **aircraft** - Type of aircraft\n",
        "7. **traveller_type** - Type of traveller\n",
        "8. **cabin**- Cabin type chosen by traveller (Economy, Business,Premium economy,First class)\n",
        "9. **route** - Route flown by flyer\n",
        "10. **date_flown** - Date of travel\n",
        "11. **seat_comfort** - Rating provided towards seat comfort\n",
        "12. **cabin_service** - Rating provided towards cabin service.\n",
        "13. **food_bev** - Rating provided towards food and beverages supplied during travel.\n",
        "14. **entertainment** - Rating provided towards on board flight entertainment\n",
        "15. **ground_service** - Rating provided towards ground service staff.\n",
        "16. **value_for_money** - Rating provided towards value for money.\n",
        "17. **recommended** - Airline service Recommended by flyer (Yes/No)"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df1.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df1.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It has lot of blank rows with many null values and the columns description are as follows:\n",
        "\n",
        "1. **airline** - Name of the airline.  (**object type**)\n",
        "2. **overall** - Overall rating defined by customer. (**float type**)\n",
        "3. **Author** - Customer information. (**object type**)\n",
        "4. **review_date** - date on which customer posted a review. (**object type**)\n",
        "5. **Customer_review** - Description of customer review. (**object type**)\n",
        "6. **aircraft** - Type of aircraft. (**object type**)\n",
        "7. **traveller_type** - Type of traveller. (**object type**)\n",
        "8. **cabin**- Cabin type chosen by traveller. (Economy, Business,Premium economy,First class) (**object type**)\n",
        "9. **route** - Route flown by flyer. (**object type**)\n",
        "10. **date_flown** - Date of travel. (**object type**)\n",
        "11. **seat_comfort** - Rating provided towards seat comfort. (**float type**)\n",
        "12. **cabin_service** - Rating provided towards cabin service. (**float type**)\n",
        "13. **food_bev** - Rating provided towards food and beverages supplied during travel. (**float type**)\n",
        "14. **entertainment** - Rating provided towards on board flight entertainment. (**float type**)\n",
        "15. **ground_service** - Rating provided towards ground service staff. (**float type**)\n",
        "16. **value_for_money** - Rating provided towards value for money. (**float type**)\n",
        "17. **recommended** - Airline service Recommended by flyer (Yes/No). (**object type**)"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in df1.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df1[i].nunique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a copy of your dataset for in future revert back\n",
        "df=df1.copy()"
      ],
      "metadata": {
        "id": "kCgtMVA34asD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop all duplicated rows as there are many blank and duplicated rows\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "X-_WQHAQ4hM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop the index column\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "5eEAXyLi4mae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we checked the shape of data after dropping.\n",
        "#Check for shape of your dataset\n",
        "df.shape"
      ],
      "metadata": {
        "id": "0732Nzky4pfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now check for sum of NaN values and sort it according to the sum.\n",
        "#check for null values and sort in ascending order\n",
        "df.isnull().sum().sort_values(ascending=False)\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we are dropping our unwanted columns like `author`, `customer_review`, `route`.\n",
        "df.drop(columns=(['author','customer_review','route']),axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "4ZvkKrIO5U9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are dropping our `aircraft` column because it almost have `70% NaN values`.\n",
        "df.drop(columns=['aircraft'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "WWaEPt585U4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Again check for null values and sort in ascending order\n",
        "df.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "8wZwTRwN5U0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are droping nan values rows for these two columns named `ground_service` and `entertainment`.\n",
        "df.dropna(subset=['ground_service','entertainment'],inplace=True)"
      ],
      "metadata": {
        "id": "57vXR6cp5Uu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fill the null vales with mean fo their rating\n",
        "df['food_bev'].fillna(df['food_bev'].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "tbVG60vt5UqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop all null values in our whole dataset\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "xKhYLFEX5Ukw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final check for null values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "VfTwy7XA5UYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for shape after cleaning or dataset\n",
        "df.shape"
      ],
      "metadata": {
        "id": "zvWcoipW6Wg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First row is all null values so after we dropped it our index starts from 1 so we are resetting or index\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "8QNNv_P36cHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check first 5 rows of dataset after cleaning\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rp8F0dW56kYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "xT-TjfDE67DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we can see there are many variables having not appropriate datatypes so we changed them to their suitable datatypes\n",
        "d_type={'overall':'int8','review_date':'datetime64[ns]','seat_comfort':'int8','cabin_service':'int8','food_bev':'int8','entertainment':'int8',\n",
        "        'ground_service':'int8',\n",
        "        'value_for_money':'int8'}\n",
        "for i,j in d_type.items():\n",
        "  df[i]=df[i].astype(j)"
      ],
      "metadata": {
        "id": "7A3XYBRg66_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here converted `date_flown` column in a proper date format by removing timestamp and changed to Datetime format.\n",
        "df['date_flown']=pd.to_datetime(df['date_flown'], errors='coerce')"
      ],
      "metadata": {
        "id": "1gT1UMUb669Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Renamed `overall` to `overall_rating` and `date_flown` to `departure_date` for better understanding.\n",
        "df.rename(columns={'overall':'overall_rating','date_flown':'departure_date'},inplace=True)"
      ],
      "metadata": {
        "id": "a0DRaDg966eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n"
      ],
      "metadata": {
        "id": "XP82pbQv72_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Converted Date columns to datetime format as they were in object datatype and converted various rating columns from float to int as all ratings are only in integers.\n",
        "2. date_flown column was not in proper date format it also contained Timestamp so we changed to a proper date format by removing timestamp and converted it into datetime datatype.\n",
        "3. Renamed overall to overall_rating and date_flown to departure_date for better understanding."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "\n",
        "# Count the occurrences of each airline and reset the index\n",
        "air_cnt = df['airline'].value_counts().sort_values(ascending=False).head(10).reset_index()\n",
        "air_cnt.columns = ['airline', 'count']  # Rename columns for clarity\n",
        "\n",
        "# Create a bar plot\n",
        "palette = sns.color_palette(\"Set1\", 10)\n",
        "ax = sns.barplot(x=air_cnt['airline'], y=air_cnt['count'], palette=palette)\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Airlines', fontsize=12)\n",
        "plt.ylabel('Number of Trips', fontsize=12)\n",
        "plt.title('Top 10 Airlines Based on Highest Trips', fontsize=18)\n",
        "\n",
        "# Add bar labels\n",
        "for num in ax.containers:\n",
        "    ax.bar_label(num)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Cp584SZm9OAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Bar graph` is typically used when we have to depict categorical values with numerical values and here it suits well as we are to show airlines with its count of reviews"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have shown `top 10 airlines` in terms of their reviews count and can understand that `American Airlines` has the most number of review i.e.1412 reviews followed by `United Airlines` having 1358 reviews and `Bristish Airways` having 1271 reviews."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's essential to consider the nature of the reviews, the sentiments expressed, Understanding what customers appreciate about an airline, whether it's excellent service, punctuality, or other positive aspects, can help the company leverage and enhance these strengths and Identifying common issues or complaints allows the airline to address and rectify problems, leading to an improved customer experience."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cab_cnt=df['cabin'].value_counts().reset_index()"
      ],
      "metadata": {
        "id": "8b-qBhsG-Gdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cab_cnt.head())"
      ],
      "metadata": {
        "id": "xF9x19zb-hJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cab_cnt = df['cabin'].value_counts().reset_index()\n",
        "cab_cnt.columns = ['cabin', 'count']"
      ],
      "metadata": {
        "id": "JsVhdiF2-r9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 :` Pie chart` for showing distribution of diffrent cabin classes preffered by passengers\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.pie(\n",
        "    cab_cnt['count'],  # Use the column with numeric values\n",
        "    labels=cab_cnt['cabin'],  # Use the column with labels\n",
        "    autopct='%1.1f%%',\n",
        "    explode=[0, 0, 0.12, 0.2],\n",
        "    startangle=60,\n",
        "    textprops={'fontsize': 10},\n",
        "    shadow=True,\n",
        "    wedgeprops={'edgecolor': 'white'}\n",
        ")\n",
        "plt.title('Distribution of Different Cabin Classes Preferred by Passengers', y=1.08, fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nZB_21Vi-t9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A `pie chart` is a circular statistical graphic that is divided into slices to illustrate numerical proportions. It's primarily used to show the relationship of parts to a whole."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart we can see that `econony class`(72.5%) constitues the largest part followed by `business class`(19.4%)and the other two class `Premium`(5.2%) and `First Class`(3.0%) constitues very less portion of the chart which tells that mostly people were travelling in economy class ."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding the popularity of economy class can guide the airline in customizing services to meet the needs and expectations of this larger customer segment,Given that economy class is the most popular, marketing efforts can be targeted towards this segment. Promotions, loyalty programs, and advertising can be tailored to attract and retain economy class travelers."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 : `Bar Chart` for comparing most popular cabin type\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming df[\"traveller_type\"] exists and contains the data\n",
        "most_trav = df[\"traveller_type\"].value_counts().reset_index()\n",
        "most_trav.columns = ['traveller_type', 'count']  # Rename columns for clarity\n",
        "\n",
        "ax = sns.barplot(x=most_trav['traveller_type'], y=most_trav['count'], palette='Dark2')\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Traveller Type')\n",
        "plt.title('Most Popular Traveller Type')\n",
        "\n",
        "# Add bar labels\n",
        "for num in ax.containers:\n",
        "    ax.bar_label(num)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Bar graph` is typically used when we have to depict categorical values with numerical values and here it suits well as we are to show air"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Solo Leisure` is the most preffered travel_type by passengers while `Bussiness` is the lowest travel_type."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding that solo leisure travel is more popular allows the airline to tailor marketing efforts specifically toward this segment. Promotions, advertising, and loyalty programs can be designed to attract and retain solo leisure travelers, potentially increasing customer acquisition and retention."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#performing the grouphby method\n",
        "eda_4=df.groupby('cabin')[['food_bev','entertainment']].mean().reset_index()\n",
        "eda_4"
      ],
      "metadata": {
        "id": "NEKDeUJVBriB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 :`Side by side Bar Chart` for comparing cabin classes based on food_bev and entertainment ratings\n",
        "plt.rcParams['figure.figsize']=(10,5)\n",
        "eda_4.plot(x=\"cabin\", y=[\"food_bev\", \"entertainment\"], kind=\"bar\")\n",
        "plt.title('Cabin classes based on Food_bev and entertainment ratings')\n",
        "plt.ylabel('ratings')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Side by side Bar Chart` is best suited for showing side by side comparision of various cabin class wrt food_beverages and entertainment."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can conclude that there is no significant change in ratings of `food_bev` and `entertainment` in Economy and first_class but in premium economy class there is more rating for entertainment as compared to food_bev and vice-versa for Bussiness_class."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowing that there are different preferences for entertainment and food_bev in Premium Economy and Business Class allows the airline to focus on enhancing services in each class selectively. This could involve improving menu options, upgrading entertainment systems, or introducing new features to align with passenger expectations"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 : Distribution of diffrent types of ratings using `Voilin Plot`\n",
        "columns = ['seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money','overall_rating']\n",
        "\n",
        "# Melt the DataFrame to long format\n",
        "df_melted = df.melt(value_vars=columns, var_name='Rating Category', value_name='Rating')\n",
        "\n",
        "# Create a violin plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.violinplot(x='Rating Category', y='Rating', data=df_melted,palette='Set1')\n",
        "plt.title('Violin Plot of various type of Ratings')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize= (8,5))\n",
        "overall = df.groupby(df['airline'])['overall_rating'].mean().sort_values(ascending = False).head(10).reset_index()\n",
        "ax = sns.barplot(y=overall['airline'],x = overall['overall_rating'],palette =\"tab10\" )\n",
        "plt.xlabel('Average overall rating')\n",
        "plt.ylabel('Airline')\n",
        "plt.title('Top rated airlines')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We picked `horizontal column chart` for comparison of various airlines wrt average overall rating."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this chart we can see `Aegean airlines` is highest overall rating followed by `EVA airlines` and `ANA all Nippon Airways` while `Cathay Pecific airways` has the lowest rating ."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aegean Airlines, EVA Airlines, and ANA All Nippon Airways can continue to focus on providing excellent service to maintain their high ratings. This can include improving in-flight amenities, on-time performance, and customer service.\n",
        " Cathay Pacific Airways, being rated lower, can invest in training and development programs for its staff to enhance customer service and improve overall customer experience."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.figure(figsize= (20,5))\n",
        "val = df.groupby(df['airline'])['value_for_money'].mean().sort_values(ascending = False).head(10).reset_index()\n",
        "ax = sns.barplot(x=val['airline'],y = val['value_for_money'] ,palette = 'viridis')\n",
        "\n",
        "plt.title('Top 10 Airlines wrt to value for money',fontsize = 18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We picked `Bar chart` for comparison of various airlines wrt to Average rating of value for money."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that `EVA Air ` is the highest rated followed by China Southern Airlines and Aegean Airlines  for value for money ."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the above insightes EVA Air can offer loyalty programs or incentives for frequent flyers to encourage repeat business and enhance customer loyalty."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "sns.histplot(df['overall_rating'], kde = True,bins =5,color='#4CBB17')\n",
        "plt.title('Distribution of overall rating')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " We chose `Histogram`  for distribution of Overall rating."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can conclude that most people have rated between either 1-2 or 8-10\n",
        "it shows that passenger have either best or worst experience with airline."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on above insightes Airlines can focus on addressing the aspects that lead to extreme negative experiences, such as poor customer service, flight delays, or uncomfortable seating, to reduce the number of low ratings and engaging with customers who have provided extreme ratings (either low or high) can provide valuable feedback for improvement and allow airlines to address specific pain points or areas of excellence."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.boxplot(x=df['cabin'], y=df['cabin_service'], hue = df['recommended'])\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We picked this type of `Boxplot` to show rating comparison between diffrent cabin classes."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see for every cabin class if the service rating is more then 3 then passenger is more likely to recommend that airline to others."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By focusing on enhancing service quality across all cabin classes to ensure ratings exceed 3, airlines can improve overall customer satisfaction, leading to positive recommendations and repeat business\n",
        "\n",
        "negative-impact from insights:\n",
        "If service ratings for any cabin class consistently fall below 3, it could lead to negative word-of-mouth, lower customer satisfaction, and a decline in recommendations, which could result in a loss of customers and revenue."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize= (14,6))\n",
        "plt.title('Number of reviews over months')\n",
        "df['month_name'] = df['review_date'].dt.strftime('%B')\n",
        "df['month'] = df['review_date'].dt.month\n",
        "df2 = df[['month_name','month']].value_counts().reset_index().sort_values(by = 'month')\n",
        "df2.rename(columns={0:'count'},inplace = True)\n",
        "ax = sns.barplot(x = df2['month_name'], y = df2['count'],palette = 'Dark2')\n",
        "for num in ax.containers:\n",
        "  ax.bar_label(num)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are plotting in which month how many reviews are submitting so with the help of this we can check is there any pattern or relation of number of reviews with the month so the best suited chart is a `bar chart`."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can analyze from this chart that `january` month is having a large number of reviews as compared to others follwed by `july` and `august` while in the month of may we have the least may be january is a holiday or vacation month so more number of travellers are there so reviews is also there or the staff is not properly managing the services due to this reviews are more because passenger traffic is more."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For holiday months if we are having more passenger traffic so we should employ the temporary staff to not spoil our services and management if the traffic is the reason."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title('Overall rating vs cabin type')\n",
        "sns.barplot(x = df.cabin, y = df.overall_rating, hue = df['recommended'], palette= ['#00e500','red'])"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are plotting our categorical value against discrete numerical value so best suited chart is a `side by side bar chart`.\n"
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see from this that almost in all cabin type we have overall rating more than 8 and the customer recommend the airline to others while for no we have almost 2 rating overall in economy while 3 for rest of all, so there is no much difference between cabin type if we see recommend yes/no ."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can say from above insights that if a person give overall rating more than 8 then its 99% sure that he is gonna recommend the airline to others by the help of rating we can request our customer to share their opinions on airline service on some platform for recommendation, while if person is not satisfied we will try to resolve their issue with best possible solution."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "source": [
        "# Chart - 12 visualization code\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fit the encoder to the 'airline' column and transform it\n",
        "df['airline_encoded'] = le.fit_transform(df['airline'])\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.title('Correlation Heatmap')\n",
        "\n",
        "# Calculate correlation using only numerical columns, including the encoded airline column.\n",
        "# We explicitly select the numerical columns using `.select_dtypes(include=np.number)`\n",
        "# to avoid the error.\n",
        "sns.heatmap(df.select_dtypes(include=np.number).corr(), annot=True, fmt='.2f', annot_kws={'size': 10}, vmax=1, square=True, cmap=\"rocket\")\n",
        "\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "v6fanhroG_tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This particular graph is the most powerful visualisation as it depicts the relationship of all the columns with each other and one another too."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "# Pair Plot visualization code\n",
        "column_name = [ 'seat_comfort','value_for_money','cabin_service','ground_service']\n",
        "pairplot_data = df[column_name]\n",
        "chart15=sns.pairplot(pairplot_data,kind = 'reg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Calculate the means and standard deviations of the two halves\n",
        "mean1 = (df[df['airline']=='Qatar Airways']['overall_rating']).mean()\n",
        "mean2 = (df[df['airline']=='EVA Air']['overall_rating']).mean()\n",
        "std1 = (df[df['airline']=='Qatar Airways']['overall_rating']).std()\n",
        "std2 = (df[df['airline']=='EVA Air']['overall_rating']).std()\n",
        "\n",
        "# Calculate the sample sizes\n",
        "n1 = (df[df['airline']=='Qatar Airways']['overall_rating']).count()\n",
        "n2 = (df[df['airline']=='EVA Air']['overall_rating']).count()\n",
        "\n",
        "#Calculate the standard error for each airline\n",
        "se1 = std1 / np.sqrt(n1)\n",
        "se2 = std2 / np.sqrt(n2)\n",
        "\n",
        "# Calculate the standard error of the difference between means\n",
        "standard_error = np.sqrt(se1**2 + se2**2)\n",
        "\n",
        "# Calculate the t_test\n",
        "t_stat = (mean1 - mean2) / standard_error\n",
        "\n",
        "#Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "#Degree of freedom\n",
        "dodf = n1 + n2 - 2\n",
        "\n",
        "#calculating probability point function\n",
        "cv = stats.t.ppf(1.0 - alpha, dodf)\n",
        "\n",
        "# Calculate the p-value (two-tailed test)\n",
        "p_value = (1 - stats.t.cdf(abs(t_stat), dodf)) * 2\n",
        "\n",
        "# Set the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "print('The p value for 0.05 significance level is {:.5f}'.format(p_value))\n",
        "\n",
        "# Compare the p-value with the significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference in overall rating of two airlines.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference in overall rating of two airlines.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We performed T-Test for this hypothesis testing to obtain P-value."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " We have a sample dataset and we are making inference about population and our population parameters are not known to us and to compare the overall ratings of the two selected airlines."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Null Hypothesis (H0): There is no association between the traveller type and the likelihood of recommending the airline.\n",
        "\n",
        "\n",
        "* Alternative Hypothesis (H1): There is an association between the traveller type and the likelihood of recommending the airline."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "contingency_table = pd.crosstab(df['traveller_type'], df['recommended'])\n",
        "\n",
        "# Perform chi-square test\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "# Output the results\n",
        "print(f'Chi-square statistic: {chi2}')\n",
        "print(f'P-value: {p}')\n",
        "print(f'Degrees of freedom: {dof}')\n",
        "\n",
        "\n",
        "# Compare the p-value with the significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is an association between the traveller type and the likelihood of recommending the airline.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no association between the traveller type and the likelihood of recommending the airline.\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We performed Chi-square Test for this hypothesis testing to obtain P-value."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A chi-square test of independence can be used to determine if there is a significant association between the type of traveler and their recommendation status."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Null Hypothesis (H):** Seat comfort ratings do not vary across different cabin classes.  \n",
        "- **Alternative Hypothesis (H):** Seat comfort ratings significantly differ among cabin classes."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Perform one-way ANOVA\n",
        "f_statistic, p_value = f_oneway(df['seat_comfort'][df['cabin'] == 'First Class'],\n",
        "                                df['seat_comfort'][df['cabin'] == 'Business Class'],\n",
        "                                df['seat_comfort'][df['cabin'] == 'Premium Economy'],\n",
        "                                df['seat_comfort'][df['cabin'] == 'Economy Class'])\n",
        "\n",
        "# Set significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "\n",
        "print(\"\\nResults:\")\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"P-value: \",p_value)\n",
        "\n",
        "# Check for statistical significance\n",
        "if p_value < alpha:\n",
        "    print(\"\\nResult: Reject the null hypothesis. There is a significant difference in seat comfort ratings.\")\n",
        "else:\n",
        "    print(\"\\nResult: Fail to reject the null hypothesis. No significant difference in seat comfort ratings.\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We performed One-way ANOVA Test for this hypothesis testing to obtain P-value."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A one-way ANOVA test is used to evaluate whether the average seat comfort ratings differ significantly across various cabin classes."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        " # We have already addressed the issue of missing values during the exploratory data analysis phase."
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset had no outliers so there was no need of handling as such."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "label_encode = LabelEncoder()\n",
        "df['recommended'] = label_encode.fit_transform(df['recommended'])\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ordinal_encoder = ce.OrdinalEncoder(mapping=[{'col': 'cabin', 'mapping': {'Economy Class': 1, 'Business Class': 3,'Premium Economy' : 2,'First Class' :4}}])\n",
        "df['cabin']= ordinal_encoder.fit_transform(df['cabin'])"
      ],
      "metadata": {
        "id": "j-TrLgv2rUsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoder = ce.OneHotEncoder(cols=['traveller_type'])\n",
        "df = one_hot_encoder.fit_transform(df)"
      ],
      "metadata": {
        "id": "2g1rFVCUraQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can not give categorical values in machine learning model so we need to encode them with numerical values . Wr have use different techniques of encoding for different columns\n",
        "\n",
        "\n",
        "\n",
        "*   For the **\"Traveller_Type\"** column, which appears to represent categorical data with different types of travelers (e.g., Solo Leisure), it's appropriate to use one-hot encoding. One-hot encoding is commonly used for categorical variables with multiple levels, where each level is treated as a distinct category\n",
        "\n",
        "*  For **\"Cabin\" column** : There is a clear ordinal relationship, where the\n",
        "different cabin classes have a meaningful and consistent order (e.g., Economy < Premium Economy < Business < First Class), then ordinal encoding could be a suitable choice. In this case, each category is assigned a numerical value based on its order.\n",
        "\n",
        "*  For **\"recommended\"** column : Since we have two categories like \"Yes\" and \"No, we used label encoding. Label encoding involves assigning a numerical label to each unique category. For \"Yes\" and \"No,\" you could encode them as 1 and 0, respectively.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.drop(columns = ['review_date','month_name','month','departure_date','airline'],inplace = True)"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Columns such as 'review_date' and 'departure_date' contain date or time-related information, which cannot be directly utilized by most machine learning algorithms without preprocessing.\n",
        "\n",
        "* Similarly, 'month' and 'month_name' were created for analysis purposes and are not necessary for training the model, so these columns were dropped.\n",
        "\n",
        "* The 'airline' column, representing the airline's name, is also not relevant for model training and was excluded."
      ],
      "metadata": {
        "id": "F-tzjJfys9JT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df[['overall_rating','seat_comfort','food_bev','cabin_service','entertainment','ground_service','value_for_money','recommended']].corr()"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the overall ratings because of data leakage\n",
        "df.drop('overall_rating',axis = 1 ,inplace = True)"
      ],
      "metadata": {
        "id": "PiV07ykktUQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#no need"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality reduction is a technique commonly used in machine learning and data analysis to reduce the number of features or variables in a dataset while preserving its essential information. This reduction can help alleviate computational expenses, improve model performance, and mitigate the curse of dimensionality."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "pca = PCA()\n",
        "airline_pca = pca.fit_transform(df.iloc[:,:-1])\n",
        "\n",
        "# Convert PCA components to a DataFrame for better readability\n",
        "airline_pca_df = pd.DataFrame(data=airline_pca, columns=[f'PC{i+1}' for i in range(len(df.iloc[:,:-1].columns))])\n",
        "\n",
        "# Display the first few rows of the PCA components\n",
        "airline_pca_df.head()"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA is a dimensionality reduction technique commonly used to reduce the number of dimensions in a dataset while preserving as much variance as possible. It achieves this by transforming the original features into a new set of orthogonal (uncorrelated) features called principal components."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "# Plotting the explained variance\n",
        "plt.figure(figsize=(10, 4))\n",
        "op=sns.barplot(x=range(1, len(explained_variance) + 1), y=explained_variance*100, hue=range(1, len(explained_variance) + 1),palette='colorblind',legend=False)\n",
        "plt.ylabel('Variance Percentage')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.title('PCA Explained Variance Percentage')\n",
        "for i, num in enumerate(explained_variance):\n",
        "    op.text(i, num * 100+1, f'{num*100:.2f}',ha='center')\n",
        "plt.ylim(0 , 90)\n",
        "plt.xlim(-1 , 12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WqvHdszVuXug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of Principal Component Analysis (PCA), explained_variance_ratio_ is an attribute of the PCA object that represents the amount of variance explained by each of the principal components.. This ratio indicates the proportion of the dataset's variance that lies along the corresponding principal component axis."
      ],
      "metadata": {
        "id": "d_wq302muih2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,len(explained_variance)):\n",
        "  print(f'Sum of percentage of variance of {i} columns',round(sum(explained_variance[0:i]*100),2))"
      ],
      "metadata": {
        "id": "afjerb0tutNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_2 = PCA(n_components=6)\n",
        "airline_pca_2 = pca_2.fit_transform(df.iloc[:,:-1])\n",
        "\n",
        "# Shape after reduction\n",
        "print(\"Original Shape:\", df.iloc[:,:-1].shape)\n",
        "print(\"Transformed Shape:\", airline_pca_2.shape)"
      ],
      "metadata": {
        "id": "GIKyUarOu4dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deciding the number of components (or principal components) to retain in Principal Component Analysis (PCA) involves balancing the trade-off between dimensionality reduction and the amount of variance preserved.\n",
        "\n",
        "By plotting **Cumulative explained variance** we understood the cumulative explained variance ratio as a function of the number of components. Decided   on the number of components that explains a large portion of the variance in the data (approx 90%) to 6 components. This method provides a threshold for retaining components while preserving most of the information in the original dataset."
      ],
      "metadata": {
        "id": "NnP4MemhvASC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "airline_pca_2_df = pd.DataFrame(data=airline_pca_2, columns=[f'PC{i+1}' for i in range(len(df.iloc[:,:6].columns))])"
      ],
      "metadata": {
        "id": "-Q0hUoeHu4Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "airline_pca_2_df.head(4)"
      ],
      "metadata": {
        "id": "YAIpB2wXvF8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "x = airline_pca_2_df\n",
        "y = df.iloc[:,-1]"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the datset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "P4NplWnVvjT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape of splitted datasets\n",
        "print('Shape of X_train',X_train.shape)\n",
        "print('Shape of y_train',y_train.shape)\n",
        "print('Shape of X_test',X_test.shape)\n",
        "print('Shape of y_test',y_test.shape)"
      ],
      "metadata": {
        "id": "WfQ53pwIvjPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most typical data splitting ratio is the 70-30 or 80-20 split, where the dataset is divided into a training set and a test set. The training set is used to train the model, while the test set is used to evaluate its performance.\n",
        "\n",
        "We used 70-30 Split: in this ratio, 70% of the data is usually allocated to the training set, while the remaining 30% is allocated to the test set. This split allows the model to learn from the majority of the data while still having a substantial portion reserved for evaluation."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An imbalanced dataset refers to a dataset where the distribution of classes (or categories) is not uniform. In other words, one class or category has significantly more instances (samples) than the other class or classes. In this case the classes are somewhat uniform so no need of handling."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "y.value_counts()"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset (using Iris dataset as an example)\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the Decision Tree model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the Algorithm\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "prediction = model.predict(X_test)\n",
        "\n",
        "# Print predictions\n",
        "print(\"Predictions:\", prediction)\n"
      ],
      "metadata": {
        "id": "gquZ6f7PoMdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#Checking the evaluation metrices on test data\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print(\"Accuracy on test data:\", accuracy_score(y_test, prediction))\n",
        "print(\"Precision on test data:\", precision_score(y_test, prediction, average='weighted'))\n",
        "print(\"Recall on test data:\", recall_score(y_test, prediction, average='weighted'))\n",
        "print(\"F1_score on test data:\", f1_score(y_test, prediction, average='weighted'))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Bd6IuQuCocfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model on training data and prediction on training data dataset.\n",
        "# ML Model - 1 Implementation\n",
        "\n",
        "model1 = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "prediction1 = model1.predict(X_train)"
      ],
      "metadata": {
        "id": "S_FKM6S1oq1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#Checking the evaluation metrices on test data\n",
        "print(\"Accuracy on test data:\", accuracy_score(y_test, prediction))\n",
        "print(\"Precision on test data:\", precision_score(y_test, prediction, average='weighted')) # Changed average to 'weighted'\n",
        "print(\"Recall on test data:\", recall_score(y_test, prediction, average='weighted')) # Changed average to 'weighted'\n",
        "print(\"F1_score on test data:\", f1_score(y_test, prediction, average='weighted')) # Changed average to 'weighted'"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "35ScEHFKjHLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "model1 = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "prediction1 = model1.predict(X_train)"
      ],
      "metadata": {
        "id": "uXakXtwyjegY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#variables for training and testing f1 score\n",
        "f1_dt_test = f1_score(y_test, prediction, average='weighted')\n",
        "f1_dt_train = f1_score(y_train, prediction1, average='weighted')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "pMiS8gdkkK98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a dataframe\n",
        "dt_df= pd.DataFrame([{'Decision_Tree_Test':f1_dt_test,'Decision_Tree_Train':f1_dt_train}])"
      ],
      "metadata": {
        "id": "P94zOLoFkRio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "graph=sns.barplot(dt_df)\n",
        "for bar in graph.containers:\n",
        "  graph.bar_label(bar)\n",
        "plt.title('Comparison of F1 score training and testing')\n",
        "plt.ylim(0.8,1)\n",
        "plt.yticks([i/100 for i in range(80,102,2)])\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('F1-score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2qG99tMqkcG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [2, 5, 10, 20, 30, 40],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "# Fit the Algorithm\n",
        "grid_search = GridSearchCV(dt_classifier, param_grid, cv=5, scoring='f1')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the\n",
        "best_params = grid_search.best_params_"
      ],
      "metadata": {
        "id": "qiuiDvqvs827"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [2, 5, 10, 20, 30, 40],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "# Fit the Algorithm\n",
        "grid_search = GridSearchCV(dt_classifier, param_grid, cv=5, scoring='f1')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the\n",
        "best_params = grid_search.best_params_\n",
        "best_model_rf_rs = grid_search.best_estimator_ # Assign the best estimator to best_model_rf_rs"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ai_MH4Dusq8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_rf_rs.feature_importances_\n",
        "print(best_model_rf_rs)"
      ],
      "metadata": {
        "id": "WO7nn3jKr9Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_param = best_model_rf_rs.get_params()\n",
        "curr_param"
      ],
      "metadata": {
        "id": "T67FnTGftFmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf3 = RandomForestClassifier(\n",
        "    criterion=curr_param['criterion'],\n",
        "    max_depth=curr_param['max_depth'],\n",
        "    min_samples_split=curr_param['min_samples_split'],\n",
        "    min_samples_leaf=curr_param['min_samples_leaf']\n",
        ")\n",
        "# Fit the Algorithm\n",
        "rf3.fit(X_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_rf3 =rf3.predict(X_test)"
      ],
      "metadata": {
        "id": "YyR6zi7MtV6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#Checking evaluation matrices after tuning on testing data\n",
        "print(\"Accuracy on test data:\", accuracy_score(y_test, y_pred_rf3))\n",
        "print(\"Precision on test data:\", precision_score(y_test, y_pred_rf3, average='weighted')) # Added average='weighted'\n",
        "print(\"Recall on test data:\", recall_score(y_test, y_pred_rf3, average='weighted')) # Added average='weighted'\n",
        "print(\"F1_score on test data:\", f1_score(y_test,y_pred_rf3, average='weighted')) # Added average='weighted'"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "QrdEeCebtr1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#Now we are Fitting our model on best parameter to predict on training data\n",
        "# Remove the 'splitter' parameter from curr_param\n",
        "curr_param = {k: v for k, v in curr_param.items() if k != 'splitter'}\n",
        "\n",
        "rf4 = RandomForestClassifier(**curr_param)\n",
        "\n",
        "# Fit the Algorithm\n",
        "rf4.fit(X_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_rf4 =rf4.predict(X_train)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "oQOsiZQRuRCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#Checking evaluation matrices after tuning on training data\n",
        "print(\"Accuracy on training data:\", accuracy_score(y_train, y_pred_rf4))\n",
        "print(\"Precision on training data:\", precision_score(y_train, y_pred_rf4, average='weighted')) # Added average='weighted'\n",
        "print(\"Recall on training data:\", recall_score(y_train, y_pred_rf4, average='weighted')) # Added average='weighted'\n",
        "print(\"F1_score on training data:\", f1_score(y_train,y_pred_rf4, average='weighted')) # Added average='weighted'"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2ilMQgERuo-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Confusion Matrix to check the performance of our model after hyperparameter tuning\n",
        "cfu3 = confusion_matrix(y_test, y_pred_rf3)\n",
        "ax= plt.subplot()\n",
        "# Assuming your target variable has 3 classes, update the labels accordingly\n",
        "# Replace with the actual names of your classes if they are different.\n",
        "labels = ['Class 0', 'Class 1', 'Class 2']\n",
        "sns.heatmap(cfu3, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "m0coL3P3t2P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "f1_rf_test_hyp = f1_score(y_test, y_pred_rf3, average='weighted')  # Added average='weighted'\n",
        "f1_rf_train_hyp = f1_score(y_train, y_pred_rf4, average='weighted')  # Added average='weighted'\n",
        "rf_df_hyp = pd.DataFrame([{'Random_forest_Test_Hyp': f1_rf_test_hyp, 'Random_forest_Train_Hyp': f1_rf_train_hyp}])\n",
        "rf_grf_hyp = sns.barplot(rf_df_hyp)\n",
        "for bar in rf_grf_hyp.containers:\n",
        "    rf_grf_hyp.bar_label(bar)\n",
        "plt.title('Comparison of F1 score on training and testing data after tuning')\n",
        "plt.xlabel('type of data')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.ylim(0.8, 1)\n",
        "plt.yticks([i / 100 for i in range(80, 102, 2)])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "FBU_CEmqxPoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_fea = RandomForestClassifier()\n",
        "rf_fea.fit(df.iloc[:,:-1],df.iloc[:,-1:])\n",
        "rf_fea_imp = rf_fea.feature_importances_\n",
        "indices = np.argsort(rf_fea_imp)\n",
        "features =df.iloc[:,:-1].columns"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the feature importance\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(len(indices)), rf_fea_imp[indices], color='red', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RF3rn24YwxtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset consists of airline reviews spanning from 2006 to 2019, covering various popular airlines worldwide. It comprises 131,895 rows and 17 columns. To enhance data quality, you performed several data preprocessing steps, including converting date columns to datetime format, adjusting rating columns, and addressing issues with the \"date_flown\" column and tackling our NaN values.\n",
        "\n",
        "During Exploratory Data Analysis (EDA), you discovered that the majority of customers (72%) opt for the economic class, followed by 19.4% in business class. Ratings predominantly fall within the 1-5 range, except for the \"overall_rating,\" which ranges from 1-10. Insights from the EDA process informed your subsequent hypothesis testing, where t-tests, chi-square, and ANOVA tests were employed to validate assumptions.\n",
        "\n",
        "Feature engineering involved encoding categorical variables and implementing Principal Component Analysis (PCA) for dimensionality reduction. The decision to retain only the first six principal components, explaining 92% of the data variance, allows for a more streamlined dataset with reduced complexity. Finally, the data was split into a training set (70%) and a testing set (30%) for model development and evaluation.\n",
        "\n",
        "For the classification problem, four models were employed: `Decision Tree`, `KNN`, `SVM`, and `Random Forest`. Initially, the Decision Tree model exhibited overfitting, but through cross-validation and hyperparameter tuning, this issue was mitigated. Subsequent models, including KNN, SVM, and Random Forest, were then applied.\n",
        "\n",
        "In terms of classification metrics, the business context prioritized F1_score, followed by Precision and Recall, with accuracy considered third. All four models achieved accuracy rates exceeding 90%, and after evaluation, SVM emerged as the top-performing model by a slight margin.\n",
        "\n",
        "The evaluation metrics comparison highlighted SVM's superior accuracy, making it the preferred choice among the models tested. Notably, the most influential features contributing to predictions were identified as \"Value for money\" and \"ground_service.\"\n",
        "\n",
        "The developed classifier models are valuable for predicting passenger referrals, allowing airlines to identify impactful passengers who can potentially bring in more revenue. The insights gained from the models suggest that improving cabin service, ground service, food and beverage offerings, entertainment, and seat comfort will enhance the likelihood of passengers recommending the airline to others. This strategic focus on key features can contribute to business growth and increased customer satisfaction."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}